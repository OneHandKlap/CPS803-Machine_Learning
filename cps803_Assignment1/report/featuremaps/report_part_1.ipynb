{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.5 64-bit",
   "display_name": "Python 3.7.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ee281cb53e290cd410f83e73a5b8e9f690eedfb23c5850a3af4ff3e2bd325b15"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Assignment 1\n",
    "P. Adam Aboud\n",
    "500883647"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from IPython.display import Image\n",
    "Image('img/picture.png')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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\n",
      "text/plain": "&lt;IPython.core.display.Image object&gt;"
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "source": [
    "1.1"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "source": [
    "![title](img/picture.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.seterr(all='raise')\n",
    "\n",
    "\n",
    "factor = 2.0\n",
    "\n",
    "class LinearModel(object):\n",
    "    \"\"\"Base class for linear models.\"\"\"\n",
    "\n",
    "    def __init__(self, theta=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            theta: Weights vector for the model.\n",
    "        \"\"\"\n",
    "        self.theta = theta\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Run solver to fit linear model. You have to update the value of\n",
    "        self.theta using the normal equations.\n",
    "\n",
    "        Args:\n",
    "            X: Training example inputs. Shape (n_examples, dim).\n",
    "            y: Training example labels. Shape (n_examples,).\n",
    "        \"\"\"\n",
    "        # *** START CODE HERE ***\n",
    "        #matrix X\n",
    "        \n",
    "        data=np.array(X)\n",
    "       \n",
    "\n",
    "        \n",
    "        #print(data)\n",
    "\n",
    "        #transpose\n",
    "        data.T\n",
    "        #dot product of x transpose and x\n",
    "        xTx=data.T.dot(data)\n",
    "\n",
    "        #inverse\n",
    "        XtX=np.linalg.inv(xTx)\n",
    "\n",
    "        #dot product of XtX and xT\n",
    "        XtX_xT=XtX.dot(data.T)\n",
    "\n",
    "        #get thetas\n",
    "        self.theta=XtX_xT.dot(y)\n",
    "        #print(self.theta)\n",
    "        \n",
    "\n",
    "\n",
    "        return self.theta\n",
    "        \n",
    "            \n",
    "        # *** END CODE HERE ***\n",
    "\n",
    "    def fit_GD(self, X, y, learning_rate=0.000002, iterations=1000):\n",
    "        \"\"\"Run solver to fit linear model. You have to update the value of\n",
    "        self.theta using the gradient descent algorithm.\n",
    "\n",
    "        \n",
    "\n",
    "        Args:\n",
    "            X: Training example inputs. Shape (n_examples, dim).\n",
    "            y: Training example labels. Shape (n_examples,).\n",
    "        \"\"\"\n",
    "        # *** START CODE HERE ***\n",
    "        count=0\n",
    "        \n",
    "        if self.theta==None:\n",
    "            self.theta=[0]*np.shape(X)[1]\n",
    "\n",
    "        while (count< iterations):\n",
    "            #for each feaeture\n",
    "            #print(\"ITERATION: \"+str(count))\n",
    "\n",
    "\n",
    "            for j in range(len(self.theta)):\n",
    "                \n",
    "                prediction=(self.predict(X)-y)*X[:,j]\n",
    "                #print(\"FEATURE: \" +str(j)+\" \"+str(sum(prediction)))\n",
    "\n",
    "                parameter_delta=-learning_rate*(sum(prediction))\n",
    "                #print(parameter_delta)\n",
    "                self.theta[j]=self.theta[j]+parameter_delta\n",
    "                #print(self.theta)\n",
    "            count+=1\n",
    "        print(self.theta)\n",
    "        # *** END CODE HERE ***\n",
    "\n",
    "    def fit_SGD(self, X, y,learning_rate=0.000002, iterations=1000):\n",
    "        \"\"\"Run solver to fit linear model. You have to update the value of\n",
    "        self.theta using the stochastic gradient descent algorithm.\n",
    "\n",
    "        Args:\n",
    "            X: Training example inputs. Shape (n_examples, dim).\n",
    "            y: Training example labels. Shape (n_examples,).\n",
    "        \"\"\"\n",
    "        # *** START CODE HERE ***\n",
    "        count=0\n",
    "        if self.theta==None:\n",
    "            self.theta=[0]*np.shape(X)[1]\n",
    "        while (count<iterations):\n",
    "            \n",
    "            for i in range(len(X[:,0])):\n",
    "                for j in range(len(self.theta)):\n",
    "                        \n",
    "                    prediction=(X[i].dot(self.theta)-y[i])\n",
    "                    #print(prediction)\n",
    "                    parameter_delta=learning_rate*prediction*X[i][j]\n",
    "                    \n",
    "                    #print(parameter_delta)\n",
    "                    self.theta[j]=self.theta[j]-parameter_delta\n",
    "            count+=1\n",
    "                \n",
    "        # *** END CODE HERE ***\n",
    "\n",
    "    def create_poly(self, k, X):\n",
    "        \"\"\"\n",
    "        Generates a polynomial feature map using the data x.\n",
    "        The polynomial map should have powers from 0 to k\n",
    "        Output should be a numpy array whose shape is (n_examples, k+1)\n",
    "\n",
    "        Args:\n",
    "            X: Training example inputs. Shape (n_examples, 2).\n",
    "        \"\"\"\n",
    "        # *** START CODE HERE ***\n",
    "        output=[]\n",
    "        for i in range(len(X[:,1])):\n",
    "            x=X[i][1]\n",
    "            output.append([x**l for l in range(k+1)])\n",
    "\n",
    "        return np.array(output)\n",
    "        # *** END CODE HERE ***\n",
    "\n",
    "    def create_sin(self, k, X):\n",
    "        \"\"\"\n",
    "        Generates a sin with polynomial featuremap to the data x.\n",
    "        Output should be a numpy array whose shape is (n_examples, k+2)\n",
    "\n",
    "        Args:\n",
    "            X: Training example inputs. Shape (n_examples, 2).\n",
    "        \"\"\"\n",
    "        # *** START CODE HERE ***\n",
    "        output=[]\n",
    "        for i in range(len(X[:,1])):\n",
    "            x=X[i][1]\n",
    "            poly=[x**l for l in range(k+1)]\n",
    "            poly.append(np.sin(x))\n",
    "            output.append(poly)\n",
    "        return (np.array(output))\n",
    "        # *** END CODE HERE ***\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make a prediction given new inputs x.\n",
    "        Returns the numpy array of the predictions.\n",
    "\n",
    "        Args:\n",
    "            X: Inputs of shape (n_examples, dim).\n",
    "\n",
    "        Returns:\n",
    "            Outputs of shape (n_examples,).\n",
    "        \"\"\"\n",
    "        # *** START CODE HERE ***\n",
    "        output=[]\n",
    "        #number of lines\n",
    "\n",
    "        for i in range (len(X[:,0])):\n",
    "            sum_of_predictions=0\n",
    "\n",
    "            for j in range(len(self.theta)):\n",
    "\n",
    "                sum_of_predictions+=X[i][j]*self.theta[j]\n",
    "\n",
    "            output.append(sum_of_predictions)\n",
    "        \n",
    "\n",
    "        return output\n",
    "        # *** END CODE HERE ***\n",
    "    def predict_poly(self,X):\n",
    "        output=[]\n",
    "        #number of lines\n",
    "\n",
    "        for i in range (len(X)):\n",
    "            sum_of_predictions=0\n",
    "\n",
    "            for j in range(len(self.theta)):\n",
    "\n",
    "                sum_of_predictions+=(X[i]**j)*self.theta[j]\n",
    "\n",
    "            #print(sum_of_predictions)\n",
    "            output.append(sum_of_predictions)\n",
    "        \n",
    "\n",
    "        return output\n",
    "\n",
    "    def predict_sin(self, X):\n",
    "        output=[]\n",
    "        #number of lines\n",
    "\n",
    "        for i in range (len(X)):\n",
    "            sum_of_predictions=0\n",
    "\n",
    "            for j in range(len(self.theta)):\n",
    "                if j==len(self.theta)-1:\n",
    "                    sum_of_predictions+=(np.sin(X[i]))*self.theta[j]\n",
    "                else:\n",
    "                    sum_of_predictions+=(X[i]**j)*self.theta[j]\n",
    "\n",
    "            #print(sum_of_predictions)\n",
    "            output.append(sum_of_predictions)\n",
    "        \n",
    "\n",
    "        return output\n",
    "\n",
    "def run_exp(train_path, sine=False, ks=[1, 2, 3,5,10,20], filename='plot.png',fit_type='normal',output=True):\n",
    "    train_x,train_y=util.load_dataset(train_path,add_intercept=True)\n",
    "    plot_x = np.ones([1000, 2])\n",
    "    plot_x[:, 1] = np.linspace(-factor*np.pi, factor*np.pi, 1000)\n",
    "    if output==True:\n",
    "        plt.figure()\n",
    "        plt.scatter(train_x[:, 1], train_y)\n",
    "\n",
    "\n",
    "    for k in ks:\n",
    "        '''\n",
    "        Our objective is to train models and perform predictions on plot_x data\n",
    "        '''\n",
    "        # *** START CODE HERE ***\n",
    "        try:\n",
    "            if sine==False:\n",
    "                if fit_type=='normal':\n",
    "                    model=LinearModel([0]*(k+1))\n",
    "                    training_data=model.create_poly(k,train_x)\n",
    "                    model.fit(training_data,train_y)\n",
    "                if fit_type=='GD':\n",
    "                    model=LinearModel([0]*(k+1))\n",
    "                    training_data=model.create_poly(k,train_x)\n",
    "                    model.fit_GD(training_data,train_y)\n",
    "                if fit_type=='SGD':\n",
    "                    model=LinearModel([0]*(k+1))\n",
    "                    training_data=model.create_poly(k,train_x)\n",
    "                    model.fit_SGD(training_data,train_y)\n",
    "                plot_y = model.predict_poly(plot_x[:, 1])\n",
    "            else:\n",
    "                if fit_type=='normal':\n",
    "                    model=LinearModel([0]*(k+2))\n",
    "                    training_data=model.create_sin(k,train_x)\n",
    "                    model.fit(training_data,train_y)\n",
    "                if fit_type=='GD':\n",
    "                    model=LinearModel([0]*(k+2))\n",
    "                    training_data=model.create_sin(k,train_x)\n",
    "                    model.fit_GD(training_data,train_y)\n",
    "                if fit_type=='SGD':\n",
    "                    model=LinearModel([0]*(k+2))\n",
    "                    training_data=model.create_sin(k,train_x)\n",
    "                    model.fit_SGD(training_data,train_y)\n",
    "                plot_y = model.predict_sin(plot_x[:, 1])\n",
    "\n",
    "            # *** END CODE HERE ***\n",
    "            '''\n",
    "            Here plot_y are the predictions of the linear model on the plot_x data\n",
    "            '''\n",
    "\n",
    "            plt.ylim(-2, 2)\n",
    "            plt.plot(plot_x[:, 1], plot_y, label='k=%d' % k)\n",
    "        except:\n",
    "            print(\"Error during computation\")\n",
    "    plt.title(filename.replace('.png',''))\n",
    "    plt.legend()\n",
    "    if output==True:\n",
    "        plt.savefig(filename)\n",
    "    plt.clf()\n",
    "    return(plot_x[:,1],plot_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;Figure size 432x288 with 0 Axes&gt;"
     },
     "metadata": {}
    }
   ],
   "source": [
    "def main(train_path, small_path, eval_path):\n",
    "    model=LinearModel()\n",
    "    train_x,train_y=util.load_dataset(train_path,add_intercept=True)\n",
    "    run_exp(train_path,sine=False,ks=[3],filename='img//1.2_normal_polynomial.png',fit_type='normal')\n",
    "    Image('img/1.2_normal_polynomial.png.png')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main(train_path='train.csv',\n",
    "        small_path='small.csv',\n",
    "        eval_path='test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}